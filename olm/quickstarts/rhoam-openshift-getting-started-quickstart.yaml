
apiVersion: console.openshift.io/v1
kind: ConsoleQuickStart
metadata:
  name: rhoam-devsandbox-getting-started-quickstart
spec:
  displayName: Getting Started with Red Hat OpenShift API Management
  icon: >-
    data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFk
    b2JlIElsbHVzdHJhdG9yIDI1LjIuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246
    IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5z
    PSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMu
    b3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4IgoJIHZpZXdCb3g9IjAgMCAzNyAzNyIgc3R5
    bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgMzcgMzc7IiB4bWw6c3BhY2U9InByZXNlcnZl
    Ij4KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4KCS5zdDB7ZmlsbDojRUUwMDAwO30KCS5zdDF7Zmls
    bDojRkZGRkZGO30KPC9zdHlsZT4KPGc+Cgk8cGF0aCBkPSJNMjcuNSwwLjVoLTE4Yy00Ljk3LDAt
    OSw0LjAzLTksOXYxOGMwLDQuOTcsNC4wMyw5LDksOWgxOGM0Ljk3LDAsOS00LjAzLDktOXYtMThD
    MzYuNSw0LjUzLDMyLjQ3LDAuNSwyNy41LDAuNUwyNy41LDAuNXoiCgkJLz4KCTxwYXRoIGNsYXNz
    PSJzdDAiIGQ9Ik0xNi41LDE4LjEyYy0xLjcyLDAtMy4xMi0xLjQtMy4xMi0zLjEyczEuNC0zLjEy
    LDMuMTItMy4xMnMzLjEyLDEuNCwzLjEyLDMuMTJTMTguMjIsMTguMTIsMTYuNSwxOC4xMnoKCQkg
    TTE2LjUsMTMuMTJjLTEuMDMsMC0xLjg4LDAuODQtMS44OCwxLjg4czAuODQsMS44OCwxLjg4LDEu
    ODhzMS44OC0wLjg0LDEuODgtMS44OFMxNy41MywxMy4xMiwxNi41LDEzLjEyeiIvPgoJPHBhdGgg
    Y2xhc3M9InN0MSIgZD0iTTEyLjk0LDExLjA2bC0yLTJjLTAuMDgtMC4wOC0wLjE4LTAuMTMtMC4y
    OS0wLjE1Yy0wLjAzLTAuMDEtMC4wNS0wLjAxLTAuMDctMC4wMQoJCWMtMC4xMS0wLjAxLTAuMjIt
    MC4wMS0wLjMyLDAuMDNjMCwwLDAsMCwwLDBjLTAuMDcsMC4wMy0wLjEzLDAuMDctMC4xOCwwLjEy
    Yy0wLjAxLDAuMDEtMC4wMSwwLjAxLTAuMDIsMC4wMWwtMiwyCgkJYy0wLjI0LDAuMjQtMC4yNCww
    LjY0LDAsMC44OGMwLjEyLDAuMTIsMC4yOCwwLjE4LDAuNDQsMC4xOHMwLjMyLTAuMDYsMC40NC0w
    LjE4bDAuOTMtMC45M1YyMi41YzAsMC4zNSwwLjI4LDAuNjIsMC42MiwwLjYyCgkJczAuNjItMC4y
    OCwwLjYyLTAuNjJWMTEuMDFsMC45MywwLjkzYzAuMjQsMC4yNCwwLjY0LDAuMjQsMC44OCwwQzEz
    LjE5LDExLjcsMTMuMTksMTEuMywxMi45NCwxMS4wNnoiLz4KCTxwYXRoIGNsYXNzPSJzdDAiIGQ9
    Ik0yMi41LDE4LjEyYy0wLjM0LDAtMC42Mi0wLjI4LTAuNjItMC42MnYtNWMwLTAuMzUsMC4yOC0w
    LjYyLDAuNjItMC42MnMwLjYyLDAuMjgsMC42MiwwLjYydjUKCQlDMjMuMTIsMTcuODUsMjIuODQs
    MTguMTIsMjIuNSwxOC4xMnoiLz4KCTxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik0yMC41LDI1LjEyYy0x
    LjcyLDAtMy4xMi0xLjQtMy4xMi0zLjEyczEuNC0zLjEyLDMuMTItMy4xMnMzLjEyLDEuNCwzLjEy
    LDMuMTJTMjIuMjIsMjUuMTIsMjAuNSwyNS4xMnoKCQkgTTIwLjUsMjAuMTJjLTEuMDMsMC0xLjg4
    LDAuODQtMS44OCwxLjg4czAuODQsMS44OCwxLjg4LDEuODhzMS44OC0wLjg0LDEuODgtMS44OFMy
    MS41MywyMC4xMiwyMC41LDIwLjEyeiIvPgoJPHBhdGggY2xhc3M9InN0MSIgZD0iTTI4Ljk0LDI1
    LjA2Yy0wLjI0LTAuMjQtMC42NC0wLjI0LTAuODgsMGwtMC45MywwLjkzVjEyLjVjMC0wLjM1LTAu
    MjgtMC42Mi0wLjYyLTAuNjJzLTAuNjIsMC4yOC0wLjYyLDAuNjIKCQl2MTMuNDlsLTAuOTMtMC45
    M2MtMC4yNC0wLjI0LTAuNjQtMC4yNC0wLjg4LDBjLTAuMjQsMC4yNC0wLjI0LDAuNjQsMCwwLjg4
    bDIsMmMwLjA2LDAuMDYsMC4xMywwLjExLDAuMjEsMC4xNAoJCWMwLjA4LDAuMDMsMC4xNiwwLjA1
    LDAuMjQsMC4wNWMwLjA4LDAsMC4xNi0wLjAyLDAuMjQtMC4wNWMwLDAsMCwwLDAsMGMwLjA3LTAu
    MDMsMC4xMy0wLjA3LDAuMTgtMC4xMgoJCWMwLjAxLTAuMDEsMC4wMS0wLjAxLDAuMDItMC4wMWwy
    LTJDMjkuMTksMjUuNywyOS4xOSwyNS4zLDI4Ljk0LDI1LjA2eiIvPgoJPHBhdGggY2xhc3M9InN0
    MCIgZD0iTTE0LjUsMjUuMTJjLTAuMzQsMC0wLjYyLTAuMjgtMC42Mi0wLjYydi01YzAtMC4zNSww
    LjI4LTAuNjIsMC42Mi0wLjYyczAuNjIsMC4yOCwwLjYyLDAuNjJ2NQoJCUMxNS4xMiwyNC44NSwx
    NC44NCwyNS4xMiwxNC41LDI1LjEyeiIvPgoJPHBhdGggY2xhc3M9InN0MCIgZD0iTTI2LjUsMTgu
    MTJjLTAuMzQsMC0wLjYyLTAuMjgtMC42Mi0wLjYydi01YzAtMC4zNSwwLjI4LTAuNjIsMC42Mi0w
    LjYyczAuNjIsMC4yOCwwLjYyLDAuNjJ2NQoJCUMyNy4xMiwxNy44NSwyNi44NCwxOC4xMiwyNi41
    LDE4LjEyeiIvPgoJPHBhdGggY2xhc3M9InN0MCIgZD0iTTEwLjUsMjUuMTJjLTAuMzQsMC0wLjYy
    LTAuMjgtMC42Mi0wLjYydi01YzAtMC4zNSwwLjI4LTAuNjIsMC42Mi0wLjYyczAuNjIsMC4yOCww
    LjYyLDAuNjJ2NQoJCUMxMS4xMiwyNC44NSwxMC44NCwyNS4xMiwxMC41LDI1LjEyeiIvPgo8L2c+
    Cjwvc3ZnPgo=
  tags:
    - api
    - management
  durationMinutes: 10
  description: Learn how to protect a Quarkus API using Red Hat OpenShift API Management.
  prerequisites:
    - You're using Red Hat Developer Sandbox, or have added Red Hat OpenShift API Management to your own OpenShift cluster.
  introduction: >-
    Welcome to the Red Hat OpenShift API Management Getting Started quick start. Red Hat OpenShift API Management install and manages instances of Red Hat 3scale API Management and Red Hat Single Sign-On on an OpenShift cluster.
    In this quick start, you'll deploy a Quarkus application on OpenShift, import it into Red Hat 3scale API Management using Service Discovery, and protect it using API Key security.
  tasks:
    - title: Deploy a Quarkus application
      description: >-
        To create a Quarkus application:

        1. Click on the [perspective switcher]{{highlight qs-perspective-switcher}} at the top of the navigation, and select **Developer**.
        1. In the navigation menu, click [Add]{{highlight qs-nav-add}}.
        1. Click the **Project** dropdown menu and select **Create Project** to create a project for your Quarkus application.
        1. In the **Name** field, enter a name for your new project. Then click **Create**.
        1. On the **+Add** page, click **From Git**.
        1. In the **Git Repo URL** field, add
        ```
        https://github.com/quarkusio/quarkus-quickstarts
        ```
        1. Click on **Show advanced Git options**, which will expose additional fields:
        1. Add `getting-started` to the **Context dir** field.
        1. At the end of the form, click **Create**.

      review:
        instructions: |-
          The application is represented by the light grey area with the white border.  The deployment is a white circle.  Verify that the application was successfully created:
          1. Do you see a **quarkus-quickstarts-app** application?
          1. Do you see a **quarkus-quickstarts** deployment?
        failedTaskHelp: This task isn’t verified yet. Try the task again.
      summary:
        failed: Try the steps again.
        success: Your Quarkus application has been deployed onto OpenShift.
    - title: Annotate the Quarkus application for Service Discovery
      description: >-
        Red Hat 3scale API Management supports
        To connect your applications or services to a Kafka instance in the Streams for Apache Kafka web console,
        you need to create a service account, copy and save the generated credentials, and copy and save the bootstrap server endpoint.
        You’ll use the service account information later when you configure your application.

        1. In the **Kafka Instances** page of the web console, for the relevant Kafka instance that you want to connect to,
        select the options icon (three vertical dots) and click **View connection information**.

        1. In the **Connection** page, copy the **Bootstrap server** endpoint to a secure location.
        This is the bootstrap server endpoint that you'll need for connecting to this Kafka instance.

        1. Click **Create service account** to generate the credentials that you'll use to connect to this Kafka instance.
        Provide a name, for example `my-service-account`. You can leave the description field empty. Click **Create**.

        1. Copy the generated **Client ID** and **Client Secret** to a secure location.

            IMPORTANT: The generated credentials are displayed only one time,
            so ensure that you have successfully and securely saved the copied credentials before closing the credentials window.

        1. After you save the generated credentials to a secure location, select the confirmation check box in the credentials window and close the window.

            You'll use the boostrap server and service account information that you saved to configure your application to connect to your Kafka instances when you're ready.
            For example, if you plan to use [Kafkacat](https://github.com/edenhill/kafkacat) to interact with your Kafka instance,
            you'll use this information to set your bootstrap server and client environment variables.
      review:
        instructions: |-
          Did you save the bootstrap server endpoint to a secure location?

          Did you save the client credentials to a secure location?
        failedTaskHelp: This task isn’t verified yet. Try the task again.
      summary:
        success: >-
          You have completed this task!
        failed: Try the steps again.
    - title: Creating a Kafka topic in Streams for Apache Kafka
      description: >-
        When you have a Kafka instance available, you can create Kafka topics to start producing and consuming messages in your services.

        1. In the **Kafka Instances** page of the web console, click on the name of the Kafka instance that you want to add a topic to.

        1. Click **Create topic** and follow the guided steps to define the topic details.
        Click **Next** to complete each step and click **Finish** to complete the setup.

            **Topic name**: Enter a unique topic name, such as ```my-first-kafka-topic```.

            **Partitions**: Set the number of partitions for this topic. This example sets the partition to ```1``` for a single partition.
            Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster.
            A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.

            NOTE: You can increase the number of partitions later, but you cannot decrease them.

            **Message retention**: Set the message retention time to the relevant value and increment.
            This example sets the retention to ```1 day```.
            Keep the **Retention size** set to ```Unlimited``` (the default).
            Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy.


            **Replicas**: Set the number of partition replicas for the topic and the minimum number of follower replicas that must be in sync with a partition leader.
            In the current version of Streams for Apache Kafka the values are fixed and set to ```3``` for the number of replicas and ```2``` for the in-sync replicas.
            Replicas are copies of partitions in a topic.
            Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails.
            When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.

        After you complete the topic setup, the new Kafka topic is listed in the topics table.
        You can now start producing and consuming messages to and from this topic using services that you connect to this instance.
      review:
        instructions: |-
          Is the new Kafka topic listed in the topics table?
        failedTaskHelp: This task isn’t verified yet. Try the task again.
      summary:
        success: >-
          You have completed this task!
        failed: Try the steps again.
  conclusion: >-
    Congratulations! You successfully completed the Red Hat OpenShift API Management Getting Started quick start,
    and are now ready to use the service.
